<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="https://devpika.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://devpika.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-11-10T15:01:33+00:00</updated><id>https://devpika.github.io/feed.xml</id><title type="html">DevPika’s Corner</title><subtitle>Welcome to Ayaskant Panigrahi's personal website!
</subtitle><author><name>Ayaskant Panigrahi</name><email>ayaskant.panigrahi@gmail.com</email></author><entry><title type="html">AOD Tweaks as a notification LED replacement</title><link href="https://devpika.github.io/2024/05/14/aod-tweaks/" rel="alternate" type="text/html" title="AOD Tweaks as a notification LED replacement" /><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://devpika.github.io/2024/05/14/aod-tweaks</id><content type="html" xml:base="https://devpika.github.io/2024/05/14/aod-tweaks/"><![CDATA[<p>A creative AOD hack that only turns on with notifications
<!--more--></p>

<p>Most smartphones today do not ship with a separate notification LED. My Google Pixel 6a only provides a minimal set of options to customize the AOD. While userspace apps that allow AOD customizations exist, I found their impact on the phone’s battery to be much higher than the vendor-optimized AOD built into the OS. I explored some <a href="https://github.com/Domi04151309/AlwaysOn">open-source options</a> in the hopes of adding more features and optimizing battery through <a href="https://github.com/KieronQuinn/Smartspacer">Shizuku</a> (to enable power-saving modes), however the basic idea of these custom AOD apps drawing constantly to the screen wasn’t very appealing. I found a <a href="https://medium.com/@KieronQuinn/smartspacer-at-a-glance-but-actually-useful-38ccff1e3255">great deep-dive</a> into customizable <a href="https://github.com/KieronQuinn/Smartspacer">“At A Glance” screen for Pixel phones</a>, but it wasn’t what I was looking for. Plus, as the author mentions, this hacky approach used APIs that could break in future OS releases.</p>

<p>As I was brainstorming some Notification Listener related solutions, I found <a href="https://f-droid.org/en/packages/me.lucky.aodify/">Aodify</a> which put a different spin on the same problem - why not toggle the whole AOD setting altogether? I immediately forked the <a href="https://github.com/x13a/Aodify">project on Github</a> and added a few optional switches to get the features I wanted, like ignoring DND modes and resetting notification state when screen was turned on and off. You can find my fork <a href="https://github.com/DevPika/Aodify-Next">here</a>. Other battery-saving features could be to turn off the AOD when inside the pocket, or only switch it on at regular intervals after receiving a notification.</p>]]></content><author><name>Ayaskant Panigrahi</name></author><category term="Android" /><summary type="html"><![CDATA[A creative AOD hack that only turns on with notifications]]></summary></entry><entry><title type="html">Mars Rovin’ launched on the Meta App Lab</title><link href="https://devpika.github.io/2024/05/14/mars-rovin-launch/" rel="alternate" type="text/html" title="Mars Rovin’ launched on the Meta App Lab" /><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://devpika.github.io/2024/05/14/mars-rovin-launch</id><content type="html" xml:base="https://devpika.github.io/2024/05/14/mars-rovin-launch/"><![CDATA[<p>Drive a rover around on Mars, while learning useful facts and unlocking secrets.
<!--more--></p>

<p>I am pleased to announce that Green Forest XR’s first app got approved for the Meta App lab today! As the developer leading all aspects of the app’s development from the very beginning, this is a major milestone for me. You can find details about the app <a href="https://www.meta.com/experiences/7565572596798006/">here</a>.</p>]]></content><author><name>Ayaskant Panigrahi</name></author><category term="Unity3D" /><category term="AR" /><category term="VR" /><summary type="html"><![CDATA[Drive a rover around on Mars, while learning useful facts and unlocking secrets.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://devpika.github.io/assets/images/blog/mars-rovin.png" /><media:content medium="image" url="https://devpika.github.io/assets/images/blog/mars-rovin.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Image Tracking and Camera Pose Estimation using OpenCV</title><link href="https://devpika.github.io/2024/05/05/ar-image-tracking/" rel="alternate" type="text/html" title="Image Tracking and Camera Pose Estimation using OpenCV" /><published>2024-05-05T00:00:00+00:00</published><updated>2024-05-05T00:00:00+00:00</updated><id>https://devpika.github.io/2024/05/05/ar-image-tracking</id><content type="html" xml:base="https://devpika.github.io/2024/05/05/ar-image-tracking/"><![CDATA[<p>A deep-dive into the inner workings of AR
<!--more--></p>

<video width="400" height="400" controls="" autoplay="" muted="">
  <source src="/assets/images/blog/ar-tracking.mp4" type="video/mp4" />
Your browser does not support the video tag.
</video>

<p>While we all wait for Apple to unblock WebXR on iOS Safari, developers can either use custom SLAM solutions like <a href="https://www.8thwall.com/blog/post/41173258896/how-we-engineered-ar-for-the-mobile-browser-with-8th-wall-web">the 8th Wall SDK</a> and <a href="https://www.zappar.com/">Zappar</a>, or leverage “App Clip Players” like <a href="https://www.onirix.com/">Onirix</a> or <a href="https://launch.variant3d.com/">Variant3D</a> for cross-platform WebAR. Open-source solutions like <a href="https://github.com/AR-js-org/AR.js">AR.js</a> and <a href="https://github.com/hiukim/mind-ar-js">MindAR</a> work, but are still a far cry from the stable tracking ARCore or ARKit provide.</p>

<p>In some ways, comparing native on-device tracking vs. tracking that works completely in-browser is not fair. Native SLAM alogrithms can leverage IMU and depth maps from secondary camera / LiDAR to perform Visual-Inertial / LiDAR-Visual SLAM (VISLAM / LVSLAM) and get significantly better results. Camera calibration parameters can be computed in advance and stored per vendor-model combination. WASM on browsers is bridging the computation performance gap, but GPU-accelerated Computer Vision (either through WebGL or WebGPU) is still not there yet.</p>

<p>I implemented an image tracking pipeline using Python and OpenCV to get a deeper understanding of this topic. Following <a href="https://github.com/EdwardLu2018/wasm-ar">a good open-source reference</a> I found on Github, I first compute Akaze feature descriptors of the target, and then search for matches in frames from webcam live feed. If a match is found, I compute the homography matrix. Finally, to get the calibration parameters for camera pose estimation, I store the pixel to 3D correspondences every few matches (to get varied angles and achieve a good calibration), and then use the Solve PNP algorithm. Once calibrated, we can easily place an object at location in the image, as can be seen in the demo video. Future improvements include tracking the image using optical flow algorithms like Lucas-Kanade instead of matching features every frame. Other feature descriptors like ORB and BRISK can also be explored. You can find the code in the <a href="https://github.com/DevPika/py-image-tracking">Github repo</a>.</p>]]></content><author><name>Ayaskant Panigrahi</name></author><category term="Computer Vision" /><category term="AR" /><summary type="html"><![CDATA[A deep-dive into the inner workings of AR]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://devpika.github.io/assets/images/blog/ar-tracking-thumb.jpg" /><media:content medium="image" url="https://devpika.github.io/assets/images/blog/ar-tracking-thumb.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Android app for NFC-powered eink display</title><link href="https://devpika.github.io/2024/04/15/nfc-eink/" rel="alternate" type="text/html" title="Android app for NFC-powered eink display" /><published>2024-04-15T00:00:00+00:00</published><updated>2024-04-15T00:00:00+00:00</updated><id>https://devpika.github.io/2024/04/15/nfc-eink</id><content type="html" xml:base="https://devpika.github.io/2024/04/15/nfc-eink/"><![CDATA[<p>Open-source Android app to update the batteryless eink display!
<!--more--></p>

<p>I have a love-hate relationship with batteries - while they make our lives that much more convenient, they are hard to dispose and recycle. Even rechargeable batteries lose their capacity over time. When I came across <a href="https://hackaday.com/2023/12/18/hacking-an-nfc-e-paper-display-from-waveshare-with-mystery-mcu/">a Hackaday post about</a> mysterious eink / epaper devices from Waveshare that do not need a battery to run, I was intrigued. Of course, the idea behind this is energy harvesting, which isn’t anything ground breaking. But <a href="/projects/creative-doodles-p5js/">I love “hanko” / stamp-sized</a> displays and had been eyeing the 1.54” epaper displays for a while now, so I got my hands on <a href="https://www.waveshare.com/1.54inch-nfc-powered-e-paper-bw.htm">the 1.54” model</a>. As I was waiting for the unit to ship from China, I looked into driving these displays programmatically. The app provided by Waveshare was closed-source and the <a href="https://www.waveshare.com/wiki/Android_SDK_for_NFC-Powered_e-Paper">documentation for the Android SDK </a> to interact with these displays was sparse and confusing to say the least.</p>

<p>Luckily, folks from the open-source hacker / maker community had <a href="https://github.com/joshuatz/nfc-epaper-writer">experimented with making an app for the display</a> before me, so I forked the repo and got to work. With some clever app reverse-engineering and support(!) from Waveshare, I got the NFC library working even with my 1.54” display!</p>

<p>The next challenge before me was to effectively use the red channel that was specific to this model. To begin my tests, I tried pushing a pre-dithered image created in GIMP (and later, for good measure, even ImageMagick) to the display. I ran into unexpected trouble here: the image was garbled even if it was the exact dimensions and only contained red, black and white! Hoping to troubleshoot the image BMP format (“Perhaps it doesn’t want ARGB_8888 after all?!?”), I tried flashing some of the test images from the decompiled app, but the results were still garbled. At this point, I suspected one of the steps was altering the final bitmap that was getting flashed to the display, so I set this problem aside for now. It was time to dither the image programmatically.</p>

<p>A popular <a href="https://github.com/jeffreyliu8/Native-Floyd-Steinberg-Dithering">Floyd-Steinberg Dithering library for Android</a> only supported black and white colors. While a <a href="https://github.com/makew0rld/dither">Go dithering library</a> did what I wanted, it was a tedious process to create the JNI bindings. I took this as a learning opportunity. And thus it was time to fork the Android dithering library and add color dithering! I quickly put together the C++ native bits to get this working. Since all of this is open source, I could easily deploy the library using Jitpack, similar to the original author of the library. Waveshare provides some code using runners on their Android SDK page, so I added that in for some quick games on the stability side. Less ANRs = more fun!</p>

<p>The question remained though: what was changing the final bitmap that got flashed to the display, causing the image to get garbled? I experimented with the placing the dithering after the cropping library had done its work. <em>Et voilà</em>, the image displayed correctly! Digging into this, it looks like the <a href="https://github.com/CanHub/Android-Image-Cropper">Android Cropping library</a> might have been anti-aliasing the image, which caused intermediate colors to come up. With the final bits of the dithering puzzle in place, it was time to enjoy <a href="https://www.redbubble.com/i/poster/Initial-D-AE86-JDM-Mountain-Downhill-Night-Ride-Drift-Racing-Takumi-Fujiwara-by-cowtownCOWBOY/89779285.LVTDI">an Initial D poster</a> in all its 200x200, dithered glory:</p>

<p><img src="/assets/images/blog/nfc-eink.jpg" alt="WaveShare 1.54&quot; Passive NFC-Powered EInk Display, showing an image of car from Initial D anime" /></p>

<p>Made it this far? You can find all the code for the flashing app in the <a href="https://github.com/DevPika/nfc-epaper-writer-update">Github repo for the Android app</a> and my fork of the Android library with colored dithering <a href="https://github.com/DevPika/Native-Floyd-Steinberg-Dithering">here</a>. While the dithering code is a bit of mess considering it was written within a few hours over the weekend, an easy improvement would be to pass in a custom color palette (currently only supports the original BW and BWR schemes).</p>]]></content><author><name>Ayaskant Panigrahi</name></author><category term="Android" /><category term="C++" /><summary type="html"><![CDATA[Open-source Android app to update the batteryless eink display!]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://devpika.github.io/assets/images/blog/nfc-eink.jpg" /><media:content medium="image" url="https://devpika.github.io/assets/images/blog/nfc-eink.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">More-than-human design @ MIT Reality Hack ‘24</title><link href="https://devpika.github.io/2024/01/30/mit-reality-hack/" rel="alternate" type="text/html" title="More-than-human design @ MIT Reality Hack ‘24" /><published>2024-01-30T00:00:00+00:00</published><updated>2024-01-30T00:00:00+00:00</updated><id>https://devpika.github.io/2024/01/30/mit-reality-hack</id><content type="html" xml:base="https://devpika.github.io/2024/01/30/mit-reality-hack/"><![CDATA[<p>Delta Real/ation introduces a groundbreaking approach where migrants take the lead in designing their new settlements.
<!--more--></p>

<figure class="image is-16by9"> 
    <iframe class="has-ratio" src="https://www.youtube.com/embed/Gc6RK4rxXjs?start=0&amp;showinfo=0" frameborder="0" allowfullscreen="">
    </iframe>
</figure>

<p>We combined the best features of the Meta Quest 3 and the Looking Glass Protrait to create a multi-user collaborative city-planning experience. The main goal of the prototype was to serve as a “probe” and help migrant population and stakeholders come together to imagine an inclusive more-than-human centered future.</p>

<p>You can find the source code on <a href="https://codeberg.org/reality-hack-2024/DeltaRealation">Codeberg</a>, with a more detailed write-up about our project on <a href="https://devpost.com/software/delta-real-ation">DevPost</a>.</p>

<p><img src="/assets/images/blog/mit-reality-hack2.jpeg" alt="team" /></p>]]></content><author><name>Ayaskant Panigrahi</name></author><category term="Unity3D" /><category term="AR" /><summary type="html"><![CDATA[Delta Real/ation introduces a groundbreaking approach where migrants take the lead in designing their new settlements.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://devpika.github.io/assets/images/blog/mit-reality-hack.png" /><media:content medium="image" url="https://devpika.github.io/assets/images/blog/mit-reality-hack.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Exercism’s Christmas Gift</title><link href="https://devpika.github.io/2023/12/25/exercism-challenge/" rel="alternate" type="text/html" title="Exercism’s Christmas Gift" /><published>2023-12-25T00:00:00+00:00</published><updated>2023-12-25T00:00:00+00:00</updated><id>https://devpika.github.io/2023/12/25/exercism-challenge</id><content type="html" xml:base="https://devpika.github.io/2023/12/25/exercism-challenge/"><![CDATA[<p>Badge for completing programming exercises in 12 different languages throughout 2023
<!--more--></p>

<p>I was able to complete atleast 5 exercises in 12 different (types of) programming languages throughout 2023! Exercism was running <a href="https://exercism.org/challenges/12in23">the #12in23 challenge</a>, where each month they set specific kinds of languages and exercises as themes for each month. For example, in Functional February, I got to explore functional paradigms using F#. While I wasn’t able to complete each theme in the specific months, I did a bit of a programming sprint during the winter holidays after my grad defense. My perseverance paid off and I was able to obtain <a href="https://exercism.org/profiles/DevPika/badges">the “Legendary” #12in23 badge</a>!</p>

<p><img src="/assets/images/blog/exercism-challenge-2.png" alt="Screenshot of the Exercism badge reveal" /></p>

<p>It was a fun learning experience, made more interesting by the in-depth videos every month for the specific themes. They even featured interviews with the creators(!) of the languages, from which I got to learn some of the thinking that goes into designing programming languages.</p>]]></content><author><name>Ayaskant Panigrahi</name></author><category term="Creative Coding" /><summary type="html"><![CDATA[Badge for completing programming exercises in 12 different languages throughout 2023]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://devpika.github.io/assets/images/blog/exercism-challenge.png" /><media:content medium="image" url="https://devpika.github.io/assets/images/blog/exercism-challenge.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Successful defended my MSc Thesis!</title><link href="https://devpika.github.io/2023/12/04/grad-defense/" rel="alternate" type="text/html" title="Successful defended my MSc Thesis!" /><published>2023-12-04T00:00:00+00:00</published><updated>2023-12-04T00:00:00+00:00</updated><id>https://devpika.github.io/2023/12/04/grad-defense</id><content type="html" xml:base="https://devpika.github.io/2023/12/04/grad-defense/"><![CDATA[<p>My thesis focuses on on-arm UI inside VR and passthrough AR.
<!--more--></p>

<p>I successfully presented and defended my MSc. thesis on a novel on-arm UI system control technique for VR and passthrough AR from the School of Interactive Arts and Technology, SFU. Very interesting questions and discussions looking towards the future. This is my small contribution to bring futuristic UI into reality! I consider this an early Christmas gift :-D</p>

<p>Photo of me with the Chair and my Committee Members:</p>

<p><img src="/assets/images/blog/defense.jpg" alt="Photo of me with the committee members and the chair" /></p>]]></content><author><name>Ayaskant Panigrahi</name></author><category term="AR" /><category term="VR" /><category term="Unity3D" /><category term="HCI" /><summary type="html"><![CDATA[My thesis focuses on on-arm UI inside VR and passthrough AR.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://devpika.github.io/assets/images/bio-photo.jpg" /><media:content medium="image" url="https://devpika.github.io/assets/images/bio-photo.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Fun times at Meta + AWS Hackathon 2023</title><link href="https://devpika.github.io/2023/11/17/webxr-hackathon-seattle/" rel="alternate" type="text/html" title="Fun times at Meta + AWS Hackathon 2023" /><published>2023-11-17T00:00:00+00:00</published><updated>2023-11-17T00:00:00+00:00</updated><id>https://devpika.github.io/2023/11/17/webxr-hackathon-seattle</id><content type="html" xml:base="https://devpika.github.io/2023/11/17/webxr-hackathon-seattle/"><![CDATA[<p>My team created an AR portal shooter game!
<!--more--></p>

<video width="400" height="400" controls="" autoplay="" muted="">
  <source src="/assets/images/blog/portal-shooter.mp4" type="video/mp4" />
Your browser does not support the video tag.
</video>

<p>Micheal, Rahul, Daniel and I came together to form the Reality Rebels team at the Meta + AWS Hackathon in Seattle this week. Tear your room’s walls apart with a portal &amp; shoot targets reminiscent of Zelda BotW! We used <a href="https://threlte.xyz/">threlte</a> (threejs + Svelte) to create the experience. A big shoutout to <a href="https://parks.lol/">Micheal Parks</a> for his great work integrating and maintaing the <a href="https://threlte.xyz/docs/reference/xr/getting-started">XR package for threlte</a>, which was the base for our project! He also came up with a cool soundtrack for our game, all within the hackathon timeline! While the original vision of the game included multiplayer aspects using WebRTC (which we partially got working), I had lots of fun regardless! I also got to meet with lots of talented people and learn about their experience working with WebXR and MR tech!</p>

<p>You can also find <a href="https://twitter.com/DevPika/status/1725963350918746529">my post on Twitter / X</a>.</p>]]></content><author><name>Ayaskant Panigrahi</name></author><category term="WebXR" /><category term="AR" /><category term="threejs" /><summary type="html"><![CDATA[My team created an AR portal shooter game!]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://devpika.github.io/assets/images/blog/ar-shooter.gif" /><media:content medium="image" url="https://devpika.github.io/assets/images/blog/ar-shooter.gif" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">AssemblyScript editor with GitLab snippets</title><link href="https://devpika.github.io/2023/05/07/assemblyscript-gitlab-pkce/" rel="alternate" type="text/html" title="AssemblyScript editor with GitLab snippets" /><published>2023-05-07T00:00:00+00:00</published><updated>2023-05-07T00:00:00+00:00</updated><id>https://devpika.github.io/2023/05/07/assemblyscript-gitlab-pkce</id><content type="html" xml:base="https://devpika.github.io/2023/05/07/assemblyscript-gitlab-pkce/"><![CDATA[<p>With GitLab OAuth2 PKCE authentication
<!--more--></p>

<p>As the WASI API gets a more solid shape, WebAssembly (shortened to WASM) has immense potential to become the ultimate cross-platform build target. Taking the concept forward are languages like <a href="https://assemblyscript,org">AssemblyScript</a> that make compiling code in the browser look easy!</p>

<p>Want to see the power of WebAssembly? See <a href="https://www.youtube.com/watch?v=C8j_ieOm4vE">this epic project by Peter Salomonsen</a> which offers a flexible way to create music right in the browser, including realtime MIDI input support! The project page is <a href="https://petersalomonsen.com/wasm-music/">here</a>.</p>

<p>While the editor on the AssemblyScript homepage does include a way to share the code you are working on, it would be nice to share it in a more legible format, say through GitHub Gists. This would however mean OAuth authentication in a simple client / frontend setup, so no storing of client secrets! To make it worse, GitHub doesn’t allow CORS authentication.</p>

<p>GitLab to the rescue! <a href="https://docs.gitlab.com/ee/api/oauth2.html#authorization-code-with-proof-key-for-code-exchange-pkce">GitLab supports</a> the increasingly recommended and secure <a href="https://developer.okta.com/blog/2019/08/22/okta-authjs-pkce">OAuth2 PKCE flow</a>, including CORS authentication! I have a simple integration in place already <a href="https://devpika.github.io/as-editor/">here</a> that allows an authenticated user to create public and private snippets. As I am not storing the access and refresh tokens yet, the creation flow is a bit unintuitive, requiring the user to press Create Snippet through the share menu, login through GitLab and then press the Create Snippet button again, this time with the correct content in the files. Fixing this, persisting file and project details between refreshes (through localStorage) and snippet loading are on my radar. You can find <a href="https://github.com/DevPika/as-editor">the full repo on GitHub</a>.</p>]]></content><author><name>Ayaskant Panigrahi</name></author><category term="WASM" /><category term="AssemblyScript" /><category term="Web" /><category term="OAuth" /><summary type="html"><![CDATA[With GitLab OAuth2 PKCE authentication]]></summary></entry><entry><title type="html">[WIP]#2 Passthrough AR - adding a watch!</title><link href="https://devpika.github.io/2022/12/07/wip-ar-watch/" rel="alternate" type="text/html" title="[WIP]#2 Passthrough AR - adding a watch!" /><published>2022-12-07T00:00:00+00:00</published><updated>2022-12-07T00:00:00+00:00</updated><id>https://devpika.github.io/2022/12/07/wip-ar-watch</id><content type="html" xml:base="https://devpika.github.io/2022/12/07/wip-ar-watch/"><![CDATA[<p>Bringing a customizable watch to AR!
<!--more--></p>

<p>I have always been a big fan of the different 3D UI explorations by UltraLeap (previously Leap Motion). One of them involving <a href="https://blog.leapmotion.com/northstar/">Project Northstar, the open HW/SW passthrough AR headset</a> from Leap Motion is very special to me.</p>

<video controls=""><source src="/assets/images/blog/wearable.mp4" type="video/mp4" /></video>

<p>I want to create something similar, but only this time it will all be in WebXR! I am also experimenting with adding a watch that can stand in for almost any rectangular smart watch, as I am scaling a square model based on the required aspect ratio. To make this even more dynamic, I also have an attachment point in the watch’s model where I can insert any watch face!</p>

<p><img src="/assets/images/blog/ar-watch.gif" alt="Watch in AR three js app" /></p>

<p>Maybe in the future I will be able to make the watch face completely dynamic instead of a static image - this and many other wonderful ideas can come to life when WebXR DOM Layers spec is ready! For now I will settle with <a href="https://github.com/DevPika/band7-photoface">creating watch faces for my very real Amazfit band 7</a>.</p>]]></content><author><name>Ayaskant Panigrahi</name></author><category term="AR" /><category term="threejs" /><category term="WebXR" /><category term="Watch" /><summary type="html"><![CDATA[Bringing a customizable watch to AR!]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://devpika.github.io/assets/images/blog/ar-watch.gif" /><media:content medium="image" url="https://devpika.github.io/assets/images/blog/ar-watch.gif" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>